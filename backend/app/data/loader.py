"""Regulatory data loader with caching and search capabilities"""

import json
from pathlib import Path
from typing import List, Dict, Optional
from functools import lru_cache
import logging

logger = logging.getLogger(__name__)


class RegulatoryDataLoader:
    """Loader for regulatory data with caching and search methods"""
    
    BASE_PATH = Path(__file__).parent / "regulatory"
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_mandatory_fields(cls) -> List[Dict]:
        """
        Load mandatory fields from JSON file.
        
        Returns:
            List of mandatory field dictionaries with regulatory requirements
            
        Example:
            >>> fields = RegulatoryDataLoader.load_mandatory_fields()
            >>> len(fields)
            18
        """
        return cls._load_json_file("mandatory_fields.json")
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_forbidden_phrases(cls) -> List[Dict]:
        """
        Load forbidden phrases from JSON file.
        
        Returns:
            List of forbidden phrase dictionaries with categories and penalties
            
        Example:
            >>> phrases = RegulatoryDataLoader.load_forbidden_phrases()
            >>> len(phrases)
            52
        """
        return cls._load_json_file("forbidden_phrases.json")
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_allowed_substances(cls) -> List[Dict]:
        """
        Load allowed substances from JSON file.
        
        Returns:
            List of allowed substance dictionaries with dosage limits
            
        Example:
            >>> substances = RegulatoryDataLoader.load_allowed_substances()
            >>> len(substances)
            35
        """
        return cls._load_json_file("allowed_substances.json")
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_regulatory_acts(cls) -> List[Dict]:
        """
        Load regulatory acts from JSON file.
        
        Returns:
            List of regulatory act dictionaries
            
        Example:
            >>> acts = RegulatoryDataLoader.load_regulatory_acts()
            >>> len(acts)
            4
        """
        return cls._load_json_file("regulatory_acts.json")
    
    @classmethod
    def get_field_by_name(cls, field_name: str) -> Optional[Dict]:
        """
        Get mandatory field by field name.
        
        Args:
            field_name: Field name to search for
            
        Returns:
            Field dictionary or None if not found
            
        Example:
            >>> field = RegulatoryDataLoader.get_field_by_name("edrpou_code")
            >>> field['description']
            'ĞšĞ¾Ğ´ Ğ„Ğ”Ğ ĞŸĞĞ£ Ğ²Ğ¸Ñ€Ğ¾Ğ±Ğ½Ğ¸ĞºĞ°/Ñ–Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ĞµÑ€Ğ°'
        """
        fields = cls.load_mandatory_fields()
        for field in fields:
            if field.get("field_name") == field_name:
                return field
        return None
    
    @classmethod
    def get_substance_by_name(cls, name: str) -> Optional[Dict]:
        """
        Get substance by name with fuzzy matching.
        
        Searches in:
        - substance_name
        - scientific_name
        - alternative_names (all variations)
        
        Args:
            name: Substance name to search for (case-insensitive)
            
        Returns:
            Substance dictionary or None if not found
            
        Example:
            >>> substance = RegulatoryDataLoader.get_substance_by_name("Ğ’Ñ–Ñ‚Ğ°Ğ¼Ñ–Ğ½ C")
            >>> substance['scientific_name']
            'ĞÑĞºĞ¾Ñ€Ğ±Ñ–Ğ½Ğ¾Ğ²Ğ° ĞºĞ¸ÑĞ»Ğ¾Ñ‚Ğ°'
            
            >>> substance = RegulatoryDataLoader.get_substance_by_name("ascorbic acid")
            >>> substance['substance_name']
            'Ğ’Ñ–Ñ‚Ğ°Ğ¼Ñ–Ğ½ C'
        """
        substances = cls.load_allowed_substances()
        name_lower = name.lower().strip()
        
        for substance in substances:
            # Check main name
            if substance.get("substance_name", "").lower() == name_lower:
                return substance
            
            # Check scientific name
            if substance.get("scientific_name", "").lower() == name_lower:
                return substance
            
            # Check alternative names
            alt_names = substance.get("alternative_names", [])
            for alt_name in alt_names:
                if alt_name.lower() == name_lower:
                    return substance
        
        return None
    
    @classmethod
    def get_critical_errors(cls) -> List[Dict]:
        """
        Get only mandatory fields with critical severity.
        
        Returns:
            List of critical mandatory fields
            
        Example:
            >>> critical = RegulatoryDataLoader.get_critical_errors()
            >>> all(f['criticality'] == 'critical' for f in critical)
            True
        """
        fields = cls.load_mandatory_fields()
        return [field for field in fields if field.get("criticality") == "critical"]
    
    @classmethod
    def get_forbidden_by_category(cls, category: str) -> List[Dict]:
        """
        Get forbidden phrases by category.
        
        Args:
            category: Category name (treatment, disease, medical, veiled)
            
        Returns:
            List of forbidden phrases in specified category
            
        Example:
            >>> treatment = RegulatoryDataLoader.get_forbidden_by_category("treatment")
            >>> len(treatment)
            10
        """
        phrases = cls.load_forbidden_phrases()
        return [phrase for phrase in phrases if phrase.get("category") == category]
    
    @classmethod
    def get_full_prompt_context(cls) -> str:
        """
        Generate full context for Claude AI prompts.
        
        Returns:
            Formatted string with all regulatory data for Claude
            
        Example:
            >>> context = RegulatoryDataLoader.get_full_prompt_context()
            >>> "ĞĞĞ ĞœĞĞ¢Ğ˜Ğ’ĞĞ Ğ‘ĞĞ—Ğ Ğ£ĞšĞ ĞĞ‡ĞĞ˜" in context
            True
        """
        acts = cls.load_regulatory_acts()
        mandatory = cls.load_mandatory_fields()
        forbidden = cls.load_forbidden_phrases()
        substances = cls.load_allowed_substances()
        
        context_parts = []
        
        # Header
        context_parts.append("â•" * 80)
        context_parts.append("ğŸ“œ ĞĞĞ ĞœĞĞ¢Ğ˜Ğ’ĞĞ Ğ‘ĞĞ—Ğ Ğ£ĞšĞ ĞĞ‡ĞĞ˜ Ğ”Ğ›Ğ¯ Ğ”Ğ†Ğ„Ğ¢Ğ˜Ğ§ĞĞ˜Ğ¥ Ğ”ĞĞ‘ĞĞ’ĞĞš")
        context_parts.append("â•" * 80)
        context_parts.append("")
        
        # Regulatory Acts
        context_parts.append("ğŸ›ï¸ Ğ Ğ•Ğ“Ğ£Ğ›Ğ¯Ğ¢ĞĞ ĞĞ† ĞĞšĞ¢Ğ˜:")
        context_parts.append("â”€" * 80)
        for act in acts:
            context_parts.append(f"\nğŸ“‹ {act['name']}")
            context_parts.append(f"   ĞĞ¾Ğ¼ĞµÑ€: {act['number']}")
            context_parts.append(f"   Ğ”Ğ°Ñ‚Ğ°: {act['date']}")
            context_parts.append(f"   ĞĞ¿Ğ¸Ñ: {act['description']}")
            if act.get('key_requirements'):
                context_parts.append("   ĞšĞ»ÑÑ‡Ğ¾Ğ²Ñ– Ğ²Ğ¸Ğ¼Ğ¾Ğ³Ğ¸:")
                for req in act['key_requirements']:
                    context_parts.append(f"   â€¢ {req}")
        
        context_parts.append("\n" + "â•" * 80)
        
        # Critical Mandatory Fields
        critical_fields = cls.get_critical_errors()
        context_parts.append(f"ğŸ”´ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§ĞĞ† ĞĞ‘ĞĞ’'Ğ¯Ğ—ĞšĞĞ’Ğ† ĞŸĞĞ›Ğ¯ (ÑˆÑ‚Ñ€Ğ°Ñ„ 640,000 Ğ³Ñ€Ğ½): {len(critical_fields)} Ğ¿Ğ¾Ğ»Ñ–Ğ²")
        context_parts.append("â”€" * 80)
        for field in critical_fields:
            context_parts.append(f"\n{field['id']}. {field['description']}")
            context_parts.append(f"   ğŸ“Œ ĞŸĞ¾Ğ»Ğµ: {field['field_name']}")
            context_parts.append(f"   ğŸ“„ Ğ”Ğ¶ĞµÑ€ĞµĞ»Ğ¾: {field['regulatory_source']}")
            context_parts.append(f"   âš ï¸ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ°: {field['error_message']}")
            context_parts.append(f"   ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ: {field['recommendation']}")
            if field.get('search_patterns'):
                patterns = ", ".join(field['search_patterns'])
                context_parts.append(f"   ğŸ” Ğ¨ÑƒĞºĞ°Ñ‚Ğ¸: {patterns}")
        
        # Warning Fields
        warning_fields = [f for f in mandatory if f.get("criticality") == "warning"]
        if warning_fields:
            context_parts.append(f"\nâš ï¸ ĞŸĞĞŸĞ•Ğ Ğ•Ğ”Ğ–Ğ•ĞĞĞ¯ (ÑˆÑ‚Ñ€Ğ°Ñ„ 62,600 Ğ³Ñ€Ğ½): {len(warning_fields)} Ğ¿Ğ¾Ğ»Ñ–Ğ²")
            context_parts.append("â”€" * 80)
            for field in warning_fields:
                context_parts.append(f"\n{field['id']}. {field['description']}")
                context_parts.append(f"   ğŸ“Œ ĞŸĞ¾Ğ»Ğµ: {field['field_name']}")
                context_parts.append(f"   ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ: {field['recommendation']}")
        
        context_parts.append("\n" + "â•" * 80)
        
        # Forbidden Phrases by Category
        context_parts.append(f"âŒ Ğ—ĞĞ‘ĞĞ ĞĞĞ•ĞĞ† Ğ¤Ğ ĞĞ—Ğ˜: {len(forbidden)} Ñ„Ñ€Ğ°Ğ·")
        context_parts.append("â”€" * 80)
        
        categories = {
            "treatment": "ğŸš« Ğ›Ğ†ĞšĞ£Ğ’ĞĞĞĞ¯",
            "disease": "ğŸ¥ Ğ—ĞĞ¥Ğ’ĞĞ Ğ®Ğ’ĞĞĞĞ¯",
            "medical": "ğŸ’Š ĞœĞ•Ğ”Ğ˜Ğ§ĞĞ Ğ¢Ğ•Ğ ĞœĞ†ĞĞĞ›ĞĞ“Ğ†Ğ¯",
            "veiled": "ğŸ­ Ğ—ĞĞ’Ğ£ĞĞ›Ğ¬ĞĞ’ĞĞĞ† Ğ¢Ğ’Ğ•Ğ Ğ”Ğ–Ğ•ĞĞĞ¯"
        }
        
        for cat_key, cat_name in categories.items():
            cat_phrases = cls.get_forbidden_by_category(cat_key)
            context_parts.append(f"\n{cat_name}: {len(cat_phrases)} Ñ„Ñ€Ğ°Ğ·")
            for phrase in cat_phrases[:5]:  # Show first 5 as examples
                variations = ", ".join(phrase.get('variations', [])[:3])
                context_parts.append(f"   â€¢ '{phrase['phrase']}' (Ğ²Ğ°Ñ€Ñ–Ğ°Ñ†Ñ–Ñ—: {variations})")
                context_parts.append(f"     ĞŸĞ¾ÑÑĞ½ĞµĞ½Ğ½Ñ: {phrase['explanation']}")
                context_parts.append(f"     Ğ¨Ñ‚Ñ€Ğ°Ñ„: {phrase['penalty_amount']:,} Ğ³Ñ€Ğ½")
            if len(cat_phrases) > 5:
                context_parts.append(f"   ... Ñ‚Ğ° Ñ‰Ğµ {len(cat_phrases) - 5} Ñ„Ñ€Ğ°Ğ· Ñƒ Ñ†Ñ–Ğ¹ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ—")
        
        context_parts.append("\n" + "â•" * 80)
        
        # Allowed Substances by Category
        context_parts.append(f"âœ… Ğ”ĞĞ—Ğ’ĞĞ›Ğ•ĞĞ† Ğ Ğ•Ğ§ĞĞ’Ğ˜ĞĞ˜: {len(substances)} Ñ€ĞµÑ‡Ğ¾Ğ²Ğ¸Ğ½")
        context_parts.append("â”€" * 80)
        
        substance_categories = {}
        for substance in substances:
            cat = substance.get('category', 'other')
            if cat not in substance_categories:
                substance_categories[cat] = []
            substance_categories[cat].append(substance)
        
        cat_names = {
            'vitamin': 'ğŸ’Š Ğ’Ğ†Ğ¢ĞĞœĞ†ĞĞ˜',
            'mineral': 'âš—ï¸ ĞœĞ†ĞĞ•Ğ ĞĞ›Ğ˜',
            'fatty_acid': 'ğŸŸ Ğ–Ğ˜Ğ ĞĞ† ĞšĞ˜Ğ¡Ğ›ĞĞ¢Ğ˜',
            'coenzyme': 'ğŸ”¬ ĞšĞĞ•ĞĞ—Ğ˜ĞœĞ˜',
            'amino_acid': 'ğŸ§¬ ĞĞœĞ†ĞĞĞšĞ˜Ğ¡Ğ›ĞĞ¢Ğ˜',
            'amino_sugar': 'ğŸ¬ ĞĞœĞ†ĞĞ¦Ğ£ĞšĞ Ğ˜',
            'glycosaminoglycan': 'ğŸ¦´ Ğ“Ğ›Ğ†ĞšĞĞ—ĞĞœĞ†ĞĞĞ“Ğ›Ğ†ĞšĞĞĞ˜',
            'carotenoid': 'ğŸ¥• ĞšĞĞ ĞĞ¢Ğ˜ĞĞĞ‡Ğ”Ğ˜',
            'probiotic': 'ğŸ¦  ĞŸĞ ĞĞ‘Ğ†ĞĞ¢Ğ˜ĞšĞ˜'
        }
        
        for cat_key, cat_substances in substance_categories.items():
            cat_display = cat_names.get(cat_key, cat_key.upper())
            context_parts.append(f"\n{cat_display}: {len(cat_substances)} Ñ€ĞµÑ‡Ğ¾Ğ²Ğ¸Ğ½")
            for substance in cat_substances[:3]:  # Show first 3 as examples
                context_parts.append(
                    f"   â€¢ {substance['substance_name']} ({substance['scientific_name']}): "
                    f"Ğ¼Ğ°ĞºÑ. {substance['max_daily_dose']} {substance['unit']}/Ğ´Ğ¾Ğ±Ñƒ"
                )
            if len(cat_substances) > 3:
                context_parts.append(f"   ... Ñ‚Ğ° Ñ‰Ğµ {len(cat_substances) - 3} Ñ€ĞµÑ‡Ğ¾Ğ²Ğ¸Ğ½")
        
        context_parts.append("\n" + "â•" * 80)
        context_parts.append("ğŸ“Š ĞŸĞ†Ğ”Ğ¡Ğ£ĞœĞĞš:")
        stats = cls.get_summary_stats()
        context_parts.append(f"   â€¢ ĞĞ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ñ… Ğ°ĞºÑ‚Ñ–Ğ²: {stats['regulatory_acts']}")
        context_parts.append(f"   â€¢ ĞĞ±Ğ¾Ğ²'ÑĞ·ĞºĞ¾Ğ²Ğ¸Ñ… Ğ¿Ğ¾Ğ»Ñ–Ğ²: {stats['mandatory_fields']} "
                            f"({stats['critical_fields']} ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ñ…)")
        context_parts.append(f"   â€¢ Ğ—Ğ°Ğ±Ğ¾Ñ€Ğ¾Ğ½ĞµĞ½Ğ¸Ñ… Ñ„Ñ€Ğ°Ğ·: {stats['forbidden_phrases']}")
        context_parts.append(f"   â€¢ Ğ”Ğ¾Ğ·Ğ²Ğ¾Ğ»ĞµĞ½Ğ¸Ñ… Ñ€ĞµÑ‡Ğ¾Ğ²Ğ¸Ğ½: {stats['allowed_substances']}")
        context_parts.append("â•" * 80)
        
        return "\n".join(context_parts)
    
    @classmethod
    def get_summary_stats(cls) -> Dict:
        """
        Get summary statistics of all regulatory data.
        
        Returns:
            Dictionary with counts of each data type
            
        Example:
            >>> stats = RegulatoryDataLoader.get_summary_stats()
            >>> stats['mandatory_fields']
            18
            >>> stats['forbidden_phrases']
            52
        """
        mandatory = cls.load_mandatory_fields()
        critical = cls.get_critical_errors()
        
        return {
            "regulatory_acts": len(cls.load_regulatory_acts()),
            "mandatory_fields": len(mandatory),
            "critical_fields": len(critical),
            "warning_fields": len(mandatory) - len(critical),
            "forbidden_phrases": len(cls.load_forbidden_phrases()),
            "allowed_substances": len(cls.load_allowed_substances()),
        }
    
    @classmethod
    def _load_json_file(cls, filename: str) -> List[Dict]:
        """
        Load JSON file from regulatory directory.
        
        Args:
            filename: Name of JSON file to load
            
        Returns:
            List of dictionaries from JSON file
            
        Raises:
            FileNotFoundError: If file doesn't exist
            json.JSONDecodeError: If file is not valid JSON
        """
        file_path = cls.BASE_PATH / filename
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"Loaded {len(data)} items from {filename}")
                return data
        except FileNotFoundError:
            logger.error(f"File not found: {file_path}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in {filename}: {e}")
            return []
        except Exception as e:
            logger.error(f"Error loading {filename}: {e}", exc_info=True)
            return []
    
    @classmethod
    def clear_cache(cls):
        """
        Clear all cached data.
        
        Use this method when regulatory files are updated and need to be reloaded.
        
        Example:
            >>> RegulatoryDataLoader.clear_cache()
            >>> # Data will be reloaded on next access
        """
        cls.load_mandatory_fields.cache_clear()
        cls.load_forbidden_phrases.cache_clear()
        cls.load_allowed_substances.cache_clear()
        cls.load_regulatory_acts.cache_clear()
        logger.info("Cleared all regulatory data cache")


if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    print("â•”" + "â•" * 78 + "â•—")
    print("â•‘" + " " * 20 + "REGULATORY DATA LOADER - DEMO" + " " * 28 + "â•‘")
    print("â•š" + "â•" * 78 + "â•")
    print()
    
    # 1. Load all data
    print("ğŸ“š Loading regulatory data...")
    mandatory = RegulatoryDataLoader.load_mandatory_fields()
    forbidden = RegulatoryDataLoader.load_forbidden_phrases()
    substances = RegulatoryDataLoader.load_allowed_substances()
    acts = RegulatoryDataLoader.load_regulatory_acts()
    print(f"âœ… Loaded: {len(mandatory)} fields, {len(forbidden)} phrases, "
          f"{len(substances)} substances, {len(acts)} acts")
    print()
    
    # 2. Summary statistics
    print("ğŸ“Š Summary Statistics:")
    print("â”€" * 80)
    stats = RegulatoryDataLoader.get_summary_stats()
    for key, value in stats.items():
        print(f"   {key.replace('_', ' ').title()}: {value}")
    print()
    
    # 3. Search by field name
    print("ğŸ” Search Examples:")
    print("â”€" * 80)
    field = RegulatoryDataLoader.get_field_by_name("edrpou_code")
    if field:
        print(f"âœ“ Field 'edrpou_code':")
        print(f"  Description: {field['description']}")
        print(f"  Penalty: {field['penalty_amount']:,} Ğ³Ñ€Ğ½")
    print()
    
    # 4. Fuzzy substance search
    print("ğŸ”¬ Substance Search (fuzzy matching):")
    print("â”€" * 80)
    test_names = ["Ğ’Ñ–Ñ‚Ğ°Ğ¼Ñ–Ğ½ C", "ascorbic acid", "Ğ¦Ğ¸Ğ½Ğº", "zinc"]
    for name in test_names:
        substance = RegulatoryDataLoader.get_substance_by_name(name)
        if substance:
            print(f"âœ“ '{name}' â†’ {substance['substance_name']} "
                  f"({substance['scientific_name']}): "
                  f"max {substance['max_daily_dose']} {substance['unit']}/Ğ´ĞµĞ½ÑŒ")
    print()
    
    # 5. Critical errors
    print("ğŸ”´ Critical Mandatory Fields:")
    print("â”€" * 80)
    critical = RegulatoryDataLoader.get_critical_errors()
    print(f"Found {len(critical)} critical fields:")
    for field in critical[:3]:
        print(f"   â€¢ {field['field_name']}: {field['description']}")
    print(f"   ... and {len(critical) - 3} more")
    print()
    
    # 6. Forbidden phrases by category
    print("âŒ Forbidden Phrases by Category:")
    print("â”€" * 80)
    categories = ["treatment", "disease", "medical", "veiled"]
    for category in categories:
        phrases = RegulatoryDataLoader.get_forbidden_by_category(category)
        print(f"   {category.upper()}: {len(phrases)} phrases")
        if phrases:
            print(f"      Example: '{phrases[0]['phrase']}' â†’ "
                  f"{phrases[0]['penalty_amount']:,} Ğ³Ñ€Ğ½ penalty")
    print()
    
    # 7. Generate full prompt context
    print("ğŸ“ Generating Full Prompt Context for Claude AI...")
    print("â”€" * 80)
    context = RegulatoryDataLoader.get_full_prompt_context()
    print(f"âœ… Generated context: {len(context):,} characters")
    print()
    print("Preview (first 500 chars):")
    print(context[:500])
    print("...")
    print()
    
    # 8. Cache demonstration
    print("ğŸ’¾ Cache Management:")
    print("â”€" * 80)
    print("All data is cached with @lru_cache for performance")
    print("To reload data after file updates:")
    print(">>> RegulatoryDataLoader.clear_cache()")
    print()
    
    print("â•”" + "â•" * 78 + "â•—")
    print("â•‘" + " " * 32 + "DEMO COMPLETE" + " " * 32 + "â•‘")
    print("â•š" + "â•" * 78 + "â•")
