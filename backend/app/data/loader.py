"""Regulatory data loader with caching and search capabilities"""

import json
from pathlib import Path
from typing import List, Dict, Optional
from functools import lru_cache
import logging

logger = logging.getLogger(__name__)


class RegulatoryDataLoader:
    """Loader for regulatory data with caching and search methods"""
    
    BASE_PATH = Path(__file__).parent / "regulatory"
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_mandatory_fields(cls) -> List[Dict]:
        """
        Load mandatory fields from JSON file.
        
        Returns:
            List of mandatory field dictionaries with regulatory requirements
            
        Example:
            >>> fields = RegulatoryDataLoader.load_mandatory_fields()
            >>> len(fields)
            18
        """
        return cls._load_json_file("mandatory_fields.json")
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_forbidden_phrases(cls) -> List[Dict]:
        """
        Load forbidden phrases from JSON file.
        
        Returns:
            List of forbidden phrase dictionaries with categories and penalties
            
        Example:
            >>> phrases = RegulatoryDataLoader.load_forbidden_phrases()
            >>> len(phrases)
            52
        """
        return cls._load_json_file("forbidden_phrases.json")
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_allowed_substances(cls) -> List[Dict]:
        """
        Load allowed substances from JSON file.
        
        Returns:
            List of allowed substance dictionaries with dosage limits
            
        Example:
            >>> substances = RegulatoryDataLoader.load_allowed_substances()
            >>> len(substances)
            35
        """
        return cls._load_json_file("allowed_substances.json")
    
    @classmethod
    @lru_cache(maxsize=1)
    def load_regulatory_acts(cls) -> List[Dict]:
        """
        Load regulatory acts from JSON file.
        
        Returns:
            List of regulatory act dictionaries
            
        Example:
            >>> acts = RegulatoryDataLoader.load_regulatory_acts()
            >>> len(acts)
            4
        """
        return cls._load_json_file("regulatory_acts.json")
    
    @classmethod
    def get_field_by_name(cls, field_name: str) -> Optional[Dict]:
        """
        Get mandatory field by field name.
        
        Args:
            field_name: Field name to search for
            
        Returns:
            Field dictionary or None if not found
            
        Example:
            >>> field = RegulatoryDataLoader.get_field_by_name("edrpou_code")
            >>> field['description']
            '–ö–æ–¥ –Ñ–î–†–ü–û–£ –≤–∏—Ä–æ–±–Ω–∏–∫–∞/—ñ–º–ø–æ—Ä—Ç–µ—Ä–∞'
        """
        fields = cls.load_mandatory_fields()
        for field in fields:
            if field.get("field_name") == field_name:
                return field
        return None
    
    @classmethod
    def get_substance_by_name(cls, name: str) -> Optional[Dict]:
        """
        Get substance by name with fuzzy matching.
        
        Searches in:
        - substance_name
        - scientific_name
        - alternative_names (all variations)
        
        Args:
            name: Substance name to search for (case-insensitive)
            
        Returns:
            Substance dictionary or None if not found
            
        Example:
            >>> substance = RegulatoryDataLoader.get_substance_by_name("–í—ñ—Ç–∞–º—ñ–Ω C")
            >>> substance['scientific_name']
            '–ê—Å–∫–æ—Ä–±—ñ–Ω–æ–≤–∞ –∫–∏—Å–ª–æ—Ç–∞'
            
            >>> substance = RegulatoryDataLoader.get_substance_by_name("ascorbic acid")
            >>> substance['substance_name']
            '–í—ñ—Ç–∞–º—ñ–Ω C'
        """
        substances = cls.load_allowed_substances()
        name_lower = name.lower().strip()
        
        for substance in substances:
            # Check main name
            if substance.get("substance_name", "").lower() == name_lower:
                return substance
            
            # Check scientific name
            if substance.get("scientific_name", "").lower() == name_lower:
                return substance
            
            # Check alternative names
            alt_names = substance.get("alternative_names", [])
            for alt_name in alt_names:
                if alt_name.lower() == name_lower:
                    return substance
        
        return None
    
    @classmethod
    def get_critical_errors(cls) -> List[Dict]:
        """
        Get only mandatory fields with critical severity.
        
        Returns:
            List of critical mandatory fields
            
        Example:
            >>> critical = RegulatoryDataLoader.get_critical_errors()
            >>> all(f['criticality'] == 'critical' for f in critical)
            True
        """
        fields = cls.load_mandatory_fields()
        return [field for field in fields if field.get("criticality") == "critical"]
    
    @classmethod
    def get_forbidden_by_category(cls, category: str) -> List[Dict]:
        """
        Get forbidden phrases by category.
        
        Args:
            category: Category name (treatment, disease, medical, veiled)
            
        Returns:
            List of forbidden phrases in specified category
            
        Example:
            >>> treatment = RegulatoryDataLoader.get_forbidden_by_category("treatment")
            >>> len(treatment)
            10
        """
        phrases = cls.load_forbidden_phrases()
        return [phrase for phrase in phrases if phrase.get("category") == category]
    
    @classmethod
    def get_full_prompt_context(cls) -> str:
        """
        Generate full context for Claude AI prompts.
        
        Returns:
            Formatted string with all regulatory data for Claude
            
        Example:
            >>> context = RegulatoryDataLoader.get_full_prompt_context()
            >>> "–ù–û–†–ú–ê–¢–ò–í–ù–ê –ë–ê–ó–ê –£–ö–†–ê–á–ù–ò" in context
            True
        """
        acts = cls.load_regulatory_acts()
        mandatory = cls.load_mandatory_fields()
        forbidden = cls.load_forbidden_phrases()
        substances = cls.load_allowed_substances()
        
        context_parts = []
        
        # Header
        context_parts.append("‚ïê" * 80)
        context_parts.append("üìú –ù–û–†–ú–ê–¢–ò–í–ù–ê –ë–ê–ó–ê –£–ö–†–ê–á–ù–ò –î–õ–Ø –î–Ü–Ñ–¢–ò–ß–ù–ò–• –î–û–ë–ê–í–û–ö")
        context_parts.append("‚ïê" * 80)
        context_parts.append("")
        
        # Regulatory Acts
        context_parts.append("üèõÔ∏è –†–ï–ì–£–õ–Ø–¢–û–†–ù–Ü –ê–ö–¢–ò:")
        context_parts.append("‚îÄ" * 80)
        for act in acts:
            context_parts.append(f"\nüìã {act['name']}")
            context_parts.append(f"   –ù–æ–º–µ—Ä: {act['number']}")
            context_parts.append(f"   –î–∞—Ç–∞: {act['date']}")
            context_parts.append(f"   –û–ø–∏—Å: {act['description']}")
            if act.get('key_requirements'):
                context_parts.append("   –ö–ª—é—á–æ–≤—ñ –≤–∏–º–æ–≥–∏:")
                for req in act['key_requirements']:
                    context_parts.append(f"   ‚Ä¢ {req}")
        
        context_parts.append("\n" + "‚ïê" * 80)
        
        # Critical Mandatory Fields
        critical_fields = cls.get_critical_errors()
        context_parts.append(f"üî¥ –ö–†–ò–¢–ò–ß–ù–Ü –û–ë–û–í'–Ø–ó–ö–û–í–Ü –ü–û–õ–Ø (—à—Ç—Ä–∞—Ñ 640,000 –≥—Ä–Ω): {len(critical_fields)} –ø–æ–ª—ñ–≤")
        context_parts.append("‚îÄ" * 80)
        for field in critical_fields:
            context_parts.append(f"\n{field['id']}. {field['description']}")
            context_parts.append(f"   üìå –ü–æ–ª–µ: {field['field_name']}")
            context_parts.append(f"   üìÑ –î–∂–µ—Ä–µ–ª–æ: {field['regulatory_source']}")
            context_parts.append(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞: {field['error_message']}")
            context_parts.append(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è: {field['recommendation']}")
            if field.get('search_patterns'):
                patterns = ", ".join(field['search_patterns'])
                context_parts.append(f"   üîç –®—É–∫–∞—Ç–∏: {patterns}")
        
        # Warning Fields
        warning_fields = [f for f in mandatory if f.get("criticality") == "warning"]
        if warning_fields:
            context_parts.append(f"\n‚ö†Ô∏è –ü–û–ü–ï–†–ï–î–ñ–ï–ù–ù–Ø (—à—Ç—Ä–∞—Ñ 62,600 –≥—Ä–Ω): {len(warning_fields)} –ø–æ–ª—ñ–≤")
            context_parts.append("‚îÄ" * 80)
            for field in warning_fields:
                context_parts.append(f"\n{field['id']}. {field['description']}")
                context_parts.append(f"   üìå –ü–æ–ª–µ: {field['field_name']}")
                context_parts.append(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è: {field['recommendation']}")
        
        context_parts.append("\n" + "‚ïê" * 80)
        
        # Forbidden Phrases by Category
        context_parts.append(f"‚ùå –ó–ê–ë–û–†–û–ù–ï–ù–Ü –§–†–ê–ó–ò: {len(forbidden)} —Ñ—Ä–∞–∑")
        context_parts.append("‚îÄ" * 80)
        
        categories = {
            "treatment": "üö´ –õ–Ü–ö–£–í–ê–ù–ù–Ø",
            "disease": "üè• –ó–ê–•–í–û–†–Æ–í–ê–ù–ù–Ø",
            "medical": "üíä –ú–ï–î–ò–ß–ù–ê –¢–ï–†–ú–Ü–ù–û–õ–û–ì–Ü–Ø",
            "veiled": "üé≠ –ó–ê–í–£–ê–õ–¨–û–í–ê–ù–Ü –¢–í–ï–†–î–ñ–ï–ù–ù–Ø"
        }
        
        for cat_key, cat_name in categories.items():
            cat_phrases = cls.get_forbidden_by_category(cat_key)
            context_parts.append(f"\n{cat_name}: {len(cat_phrases)} —Ñ—Ä–∞–∑")
            for phrase in cat_phrases[:5]:  # Show first 5 as examples
                variations = ", ".join(phrase.get('variations', [])[:3])
                context_parts.append(f"   ‚Ä¢ '{phrase['phrase']}' (–≤–∞—Ä—ñ–∞—Ü—ñ—ó: {variations})")
                context_parts.append(f"     –ü–æ—è—Å–Ω–µ–Ω–Ω—è: {phrase['explanation']}")
                context_parts.append(f"     –®—Ç—Ä–∞—Ñ: {phrase['penalty_amount']:,} –≥—Ä–Ω")
            if len(cat_phrases) > 5:
                context_parts.append(f"   ... —Ç–∞ —â–µ {len(cat_phrases) - 5} —Ñ—Ä–∞–∑ —É —Ü—ñ–π –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó")
        
        context_parts.append("\n" + "‚ïê" * 80)
        
        # Allowed Substances by Category
        context_parts.append(f"‚úÖ –î–û–ó–í–û–õ–ï–ù–Ü –†–ï–ß–û–í–ò–ù–ò: {len(substances)} —Ä–µ—á–æ–≤–∏–Ω")
        context_parts.append("‚îÄ" * 80)
        
        substance_categories = {}
        for substance in substances:
            cat = substance.get('category', 'other')
            if cat not in substance_categories:
                substance_categories[cat] = []
            substance_categories[cat].append(substance)
        
        cat_names = {
            'vitamin': 'üíä –í–Ü–¢–ê–ú–Ü–ù–ò',
            'mineral': '‚öóÔ∏è –ú–Ü–ù–ï–†–ê–õ–ò',
            'fatty_acid': 'üêü –ñ–ò–†–ù–Ü –ö–ò–°–õ–û–¢–ò',
            'coenzyme': 'üî¨ –ö–û–ï–ù–ó–ò–ú–ò',
            'amino_acid': 'üß¨ –ê–ú–Ü–ù–û–ö–ò–°–õ–û–¢–ò',
            'amino_sugar': 'üç¨ –ê–ú–Ü–ù–¶–£–ö–†–ò',
            'glycosaminoglycan': 'ü¶¥ –ì–õ–Ü–ö–û–ó–ê–ú–Ü–ù–û–ì–õ–Ü–ö–ê–ù–ò',
            'carotenoid': 'ü•ï –ö–ê–†–û–¢–ò–ù–û–á–î–ò',
            'probiotic': 'ü¶† –ü–†–û–ë–Ü–û–¢–ò–ö–ò'
        }
        
        for cat_key, cat_substances in substance_categories.items():
            cat_display = cat_names.get(cat_key, cat_key.upper())
            context_parts.append(f"\n{cat_display}: {len(cat_substances)} —Ä–µ—á–æ–≤–∏–Ω")
            for substance in cat_substances[:3]:  # Show first 3 as examples
                context_parts.append(
                    f"   ‚Ä¢ {substance['substance_name']} ({substance['scientific_name']}): "
                    f"–º–∞–∫—Å. {substance['max_daily_dose']} {substance['unit']}/–¥–æ–±—É"
                )
            if len(cat_substances) > 3:
                context_parts.append(f"   ... —Ç–∞ —â–µ {len(cat_substances) - 3} —Ä–µ—á–æ–≤–∏–Ω")
        
        context_parts.append("\n" + "‚ïê" * 80)
        context_parts.append("üìä –ü–Ü–î–°–£–ú–û–ö:")
        stats = cls.get_summary_stats()
        context_parts.append(f"   ‚Ä¢ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∏—Ö –∞–∫—Ç—ñ–≤: {stats['regulatory_acts']}")
        context_parts.append(f"   ‚Ä¢ –û–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤: {stats['mandatory_fields']} "
                            f"({stats['critical_fields']} –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö)")
        context_parts.append(f"   ‚Ä¢ –ó–∞–±–æ—Ä–æ–Ω–µ–Ω–∏—Ö —Ñ—Ä–∞–∑: {stats['forbidden_phrases']}")
        context_parts.append(f"   ‚Ä¢ –î–æ–∑–≤–æ–ª–µ–Ω–∏—Ö —Ä–µ—á–æ–≤–∏–Ω: {stats['allowed_substances']}")
        context_parts.append("‚ïê" * 80)
        
        return "\n".join(context_parts)
    
    @classmethod
    def get_summary_stats(cls) -> Dict:
        """
        Get summary statistics of all regulatory data.
        
        Returns:
            Dictionary with counts of each data type
            
        Example:
            >>> stats = RegulatoryDataLoader.get_summary_stats()
            >>> stats['mandatory_fields']
            18
            >>> stats['forbidden_phrases']
            52
        """
        mandatory = cls.load_mandatory_fields()
        critical = cls.get_critical_errors()
        
        return {
            "regulatory_acts": len(cls.load_regulatory_acts()),
            "mandatory_fields": len(mandatory),
            "critical_fields": len(critical),
            "warning_fields": len(mandatory) - len(critical),
            "forbidden_phrases": len(cls.load_forbidden_phrases()),
            "allowed_substances": len(cls.load_allowed_substances()),
        }
    
    @classmethod
    def _load_json_file(cls, filename: str) -> List[Dict]:
        """
        Load JSON file from regulatory directory.
        
        Args:
            filename: Name of JSON file to load
            
        Returns:
            List of dictionaries from JSON file
            
        Raises:
            FileNotFoundError: If file doesn't exist
            json.JSONDecodeError: If file is not valid JSON
        """
        file_path = cls.BASE_PATH / filename
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"Loaded {len(data)} items from {filename}")
                return data
        except FileNotFoundError:
            logger.error(f"File not found: {file_path}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in {filename}: {e}")
            return []
        except Exception as e:
            logger.error(f"Error loading {filename}: {e}", exc_info=True)
            return []
    
    @classmethod
    def clear_cache(cls):
        """
        Clear all cached data.
        
        Use this method when regulatory files are updated and need to be reloaded.
        
        Example:
            >>> RegulatoryDataLoader.clear_cache()
            >>> # Data will be reloaded on next access
        """
        cls.load_mandatory_fields.cache_clear()
        cls.load_forbidden_phrases.cache_clear()
        cls.load_allowed_substances.cache_clear()
        cls.load_regulatory_acts.cache_clear()
        logger.info("Cleared all regulatory data cache")


if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    print("‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 20 + "REGULATORY DATA LOADER - DEMO" + " " * 28 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù")
    print()
    
    # 1. Load all data
    print("üìö Loading regulatory data...")
    mandatory = RegulatoryDataLoader.load_mandatory_fields()
    forbidden = RegulatoryDataLoader.load_forbidden_phrases()
    substances = RegulatoryDataLoader.load_allowed_substances()
    acts = RegulatoryDataLoader.load_regulatory_acts()
    print(f"‚úÖ Loaded: {len(mandatory)} fields, {len(forbidden)} phrases, "
          f"{len(substances)} substances, {len(acts)} acts")
    print()
    
    # 2. Summary statistics
    print("üìä Summary Statistics:")
    print("‚îÄ" * 80)
    stats = RegulatoryDataLoader.get_summary_stats()
    for key, value in stats.items():
        print(f"   {key.replace('_', ' ').title()}: {value}")
    print()
    
    # 3. Search by field name
    print("üîç Search Examples:")
    print("‚îÄ" * 80)
    field = RegulatoryDataLoader.get_field_by_name("edrpou_code")
    if field:
        print(f"‚úì Field 'edrpou_code':")
        print(f"  Description: {field['description']}")
        print(f"  Penalty: {field['penalty_amount']:,} –≥—Ä–Ω")
    print()
    
    # 4. Fuzzy substance search
    print("üî¨ Substance Search (fuzzy matching):")
    print("‚îÄ" * 80)
    test_names = ["–í—ñ—Ç–∞–º—ñ–Ω C", "ascorbic acid", "–¶–∏–Ω–∫", "zinc"]
    for name in test_names:
        substance = RegulatoryDataLoader.get_substance_by_name(name)
        if substance:
            print(f"‚úì '{name}' ‚Üí {substance['substance_name']} "
                  f"({substance['scientific_name']}): "
                  f"max {substance['max_daily_dose']} {substance['unit']}/–¥–µ–Ω—å")
    print()
    
    # 5. Critical errors
    print("üî¥ Critical Mandatory Fields:")
    print("‚îÄ" * 80)
    critical = RegulatoryDataLoader.get_critical_errors()
    print(f"Found {len(critical)} critical fields:")
    for field in critical[:3]:
        print(f"   ‚Ä¢ {field['field_name']}: {field['description']}")
    print(f"   ... and {len(critical) - 3} more")
    print()
    
    # 6. Forbidden phrases by category
    print("‚ùå Forbidden Phrases by Category:")
    print("‚îÄ" * 80)
    categories = ["treatment", "disease", "medical", "veiled"]
    for category in categories:
        phrases = RegulatoryDataLoader.get_forbidden_by_category(category)
        print(f"   {category.upper()}: {len(phrases)} phrases")
        if phrases:
            print(f"      Example: '{phrases[0]['phrase']}' ‚Üí "
                  f"{phrases[0]['penalty_amount']:,} –≥—Ä–Ω penalty")
    print()
    
    # 7. Generate full prompt context
    print("üìù Generating Full Prompt Context for Claude AI...")
    print("‚îÄ" * 80)
    context = RegulatoryDataLoader.get_full_prompt_context()
    print(f"‚úÖ Generated context: {len(context):,} characters")
    print()
    print("Preview (first 500 chars):")
    print(context[:500])
    print("...")
    print()
    
    # 8. Cache demonstration
    print("üíæ Cache Management:")
    print("‚îÄ" * 80)
    print("All data is cached with @lru_cache for performance")
    print("To reload data after file updates:")
    print(">>> RegulatoryDataLoader.clear_cache()")
    print()
    
    print("‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 32 + "DEMO COMPLETE" + " " * 32 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù")
